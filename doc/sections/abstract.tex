\begin{center}
    \Large{\textbf{Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics}} \\~\\
    \Large{\textbf{By}} \\~\\
    \Large{\textbf{Natalia Koliou}} \\~\\
    
    \large{Submitted to the II-MSc “Artificial Intelligence” on \\ December 28, 2024, \\ in partial fulfillment of the \\ requirements for the MSc degree \\~\\}
\end{center}

\renewenvironment{abstract}
 {\par\noindent\textbf{\abstractname}\ \ignorespaces}
 {\par\medskip}

\begin{abstract}
    
    \vspace{5pt}
    \setlength{\parindent}{0pt}

    Game-theoretic solution concepts, such as the \emph{Nash equilibrium}, have been key to finding stable joint actions in multi-player games. However, it has been shown that the dynamics of agents' interactions, even in simple two-player games with few strategies, are incapable of reaching \emph{Nash equilibria}, exhibiting complex and unpredictable behavior. Instead, evolutionary approaches can describe the long-term persistence of strategies and filter out transient ones, accounting for the long-term dynamics of agents' interactions. Our goal is to identify agents' joint strategies that result in stable behavior, being resistant to changes, while also accounting for agents' payoffs, in dynamic games. Towards this goal, we propose transforming dynamic games into their empirical forms by considering agents' strategies instead of agents' actions, and applying the evolutionary methodology \emph{$\alpha$-Rank} to evaluate and rank strategy profiles according to their long-term dynamics. This methodology not only allows us to identify joint strategies that are strong through agents' long-term interactions, but also provides a descriptive, transparent framework regarding the high ranking of these strategies. Experiments report on agents that aim to collaboratively solve a stochastic version of the graph coloring problem. We consider different styles of play as strategies to define the empirical game, and train policies realizing these strategies, using the DQN algorithm. Then we run simulations to generate the payoff matrix required by \emph{$\alpha$-Rank} to rank joint strategies.\smalldouble
    
    \noindent
    Thesis Supervisor:  George Vouros\\
    Title: Professor, University of Piraeus\\

\end{abstract}